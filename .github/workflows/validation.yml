name: 'NuvlaEdge Validation'

on:
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref_name }}
  cancel-in-progress: true

env:
  VALIDATION_PACKAGE_NAME: "validation-latest-py3-none-any.whl"
  BRANCH_NAME: ${{ github.head_ref || github.ref_name || vars.GITHUB_REF_NAME }}

jobs:
  build-custom-validation:

    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          token: ${ secrets.VALIDATION_TOKEN_SECRET }
          repository: 'nuvlaedge/validation'

      - name: Setup Python environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Load cached poetry
        uses: actions/cache@v2.1.6
        with:
          path: ~/.local
          key: dotlocal-${{ runner.os }}-${{ hashFiles('poetry.lock') }}

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Build package
        run: poetry build --format=wheel

      - name: Create standard latest release
        run: |
          cp ./dist/validation* ./release-history/
          mv ./dist/validation* ./validation-latest-py3-none-any.whl

      - name: Save wheels and requirements as artifacts
        uses: actions/upload-artifact@v3
        with:
          name: ${{github.ref_name}}
          path: |
            dist


  setup-matrix:
    needs: build-custom-validation
    runs-on: ubuntu-latest
    outputs:
      boards: ${{ steps.set-boards.outputs.boards }}
      tests: ${{ steps.set-tests.outputs.tests }}
    steps:
      - id: set-boards
        run: |
          echo "boards=${{ vars.TESTBED_BOARDS }}" >> $GITHUB_OUTPUT

      - id: set-tests
        run: |
          echo "tests=${{ vars.VALIDATION_TESTS }}" >> $GITHUB_OUTPUT

    run-validation:
      needs: setup-matrix
      strategy:
        matrix:
          board-config: ${{ fromJSON(needs.validation-matrix.outputs.boards) }}
          validation-type: ${{ fromJSON(needs.validation-matrix.outputs.tests) }}
        fail-fast: false
      runs-on: ${{ matrix.board-config }}

      steps:
        - name: Setup Python environment
          uses: actions/setup-python@v4
          with:
            python-version: '3.10'
            cache: 'pip'

        - name: Download requirements
          uses: actions/download-artifact@v3
          with:
            name: ${{github.ref_name}}

        - name: Install Validation Framework dependency
          run: python -m pip install ${{ env.VALIDATION_PACKAGE_NAME }}  --force-reinstall

        - name: Setup results folder
          run: |
            mkdir -p results/temp/xml results/temp/json

        - name: Clear previous results
          run: |
            rm results/temp/xml/*.xml || true

        - name: Run Validation on board ${{ matrix.board-config }}
          run: |
            python -m validation_framework --target ${{ matrix.board-config }}.toml \
            --key ${{ secrets.VALIDATION_NUVLA_API_KEY }} \
            --secret ${{ secrets.VALIDATION_NUVLA_API_SECRET }} \
            --validator ${{ matrix.validation-type }} \
            --branch ${{ env.BRANCH_NAME }}

        - name: Publish Unit Test Results
          uses: EnricoMi/publish-unit-test-result-action/composite@v2
          if: always()
          with:
            check_name: "| ${{ matrix.board-config }} --- ${{ matrix.validation-type }} |"
            junit_files: "results/temp/xml/*.xml"
